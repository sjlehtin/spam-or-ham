\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[tbtags]{amsmath}
\usepackage{amssymb}
\usepackage{hyperref, url}
\usepackage{float}

\usepackage{fancyvrb}

\DefineVerbatimEnvironment {code}{Verbatim}
   {%numbers=left,numbersep=2mm,
     %frame=lines,framerule=0.1mm, 
     fontsize=\small}
\RecustomVerbatimCommand{\VerbatimInput}{VerbatimInput}
   {%numbers=left,numbersep=2mm,
     frame=lines,framerule=0.1mm, fontsize=\small}
\DefineVerbatimEnvironment {log}{Verbatim}
  {frame=lines,framerule=0.1mm, fontsize=\small}

\parindent 0mm
\parskip 3mm

% add your student number in parenthesis
\title{Decision trees versus naive Bayes in mail classification}
\author{Jori Bomanson (ZZZZZW) \\
  {\tt jori.bomanson@aalto.fi} \\
  \\
  Sami J. Lehtinen (44814P)\\ 
  {\tt sjl@iki.fi} \\
}

\begin{document}

\floatstyle{plain}
\newfloat{Listing}{t}{lol}
\floatname{Listing}{Listing}

\maketitle

Our goal in this exercise project is to compare a naive Bayes classifier
with decision trees.  We will compare learning speed and classification
accuracy, among other characteristics.

Decision trees are easy to visualize graphically and following a graph
of the tree allows to see exactly what steps the classifier takes when
it processes a sample.

The implementation of the decision tree is done with Numpy.  This
approach was chosen because we felt that Python would be better suited
in manipulating the necessary data structures.

The predictions were created with a decision tree classifier, chosen
manually from a few runs based on the accuracy of the classifier (ratio
of correctly classified samples from the validation set)\footnote{In the
  project, we will perform cross-validation to choose best classifiers
  with the training data.}.  The tree was prepruned with threshold
values in impurity and the number of columns and rows left after
splitting.

We did some manual classification checks based on the classifier output
of the test set.  Looking into the test data with \texttt{R} and
checking the flags set in the set, there were no obvious flukes with a
dozen or so rows.  Better validation procedures are necessary.

\begin{thebibliography}{9}
\bibitem{alpaydin2004}
  Ethem Alpaydin,
  \emph{Introduction to Machine Learning}.
  Massachusetts Institute of Technology, Cambridge, Massachusetts,
  1st edition,
  2004. 415 pages. ISBN 0-262-01211-1.
%\bibitem{press07}
%  William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery,
%  \emph{Numerical recipes - the art of scientific computing}.
%  Cambridge University Press, New York,
%  3rd edition,
%  2007. 1235 pages. ISBN 978-0-521-88068-8.
%\bibitem{mellin10a}
%  Ilkka Mellin, 
%  \emph{Todennäköisyyslaskenta ja tilastotiede: Kaavat}.
%  Otaniemi, 2010. 390 pages.
%\bibitem{mellin10b}
%  Ilkka Mellin, 
%  \emph{Tilastolliset taulukot}.
%  Otaniemi, 2010. 13 pages.
\end{thebibliography}

\end{document}
