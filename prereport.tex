\documentclass[a4paper,10pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[tbtags]{amsmath}
\usepackage{amssymb}
\usepackage{hyperref, url}
\usepackage{float}

\usepackage{fancyvrb}

\DefineVerbatimEnvironment {code}{Verbatim}
   {%numbers=left,numbersep=2mm,
     %frame=lines,framerule=0.1mm, 
     fontsize=\small}
\RecustomVerbatimCommand{\VerbatimInput}{VerbatimInput}
   {%numbers=left,numbersep=2mm,
     frame=lines,framerule=0.1mm, fontsize=\small}
\DefineVerbatimEnvironment {log}{Verbatim}
  {frame=lines,framerule=0.1mm, fontsize=\small}

\parindent 0mm
\parskip 3mm

% add your student number in parenthesis
\title{Decision trees versus naive Baies in mail classification}
\author{Jori Bomanson (ZZZZZW) \\
  {\tt jori.bomanson@aalto.fi} \\
  \\
  Sami J. Lehtinen (44814P)\\ 
  {\tt sjl@iki.fi} \\
}

\begin{document}

\floatstyle{plain}
\newfloat{Listing}{t}{lol}
\floatname{Listing}{Listing}

\maketitle

Our goal in this exercise project is to compare a naive Bayes classifier
with decision trees.  

Decision trees are easy to visualize graphically.

The implementation of the decision tree is done with Numpy.  This
approach was chosen because we felt that Python would be better suited
in manipulating the necessary data structures.

The preliminary data was created with a decision tree classifier, chosen
manually from a few runs on the command-line based on the accuracy of
the classifier (ratio of correctly classified samples from the
validation set).  In the project, the aim is to cross-validation to
choose best classifiers with the training data.  Cross-validation will
be performed by splitting the training data in, e.g., 10 chunks
randomly, and using each chunk in turn as the validation set and the
rest as the training set.  Part of the training data needs to be set
aside for postpruning, which is done to avoid overfitting.  Prepruning
is done with treshold values in impurity and the number of columns and
rows left after splitting.  

We did some manual classification checks based on the classifier output
of the test set.  Looking into the test data with \texttt{R} and
checking the set flags visually with command

\begin{log}
sort(colSums(data[<row>,]))
\end{log}

there were no obvious flukes with a handful of tries, although there
were some very unsure cases.

\begin{thebibliography}{9}
\bibitem{alpaydin2004}
  Ethem Alpaydin,
  \emph{Introduction to Machine Learning}.
  Massachusetts Institute of Technology, Cambridge, Massachusetts,
  1st edition,
  2004. 415 pages. ISBN 0-262-01211-1.
%\bibitem{press07}
%  William H. Press, Saul A. Teukolsky, William T. Vetterling, Brian P. Flannery,
%  \emph{Numerical recipes - the art of scientific computing}.
%  Cambridge University Press, New York,
%  3rd edition,
%  2007. 1235 pages. ISBN 978-0-521-88068-8.
%\bibitem{mellin10a}
%  Ilkka Mellin, 
%  \emph{Todennäköisyyslaskenta ja tilastotiede: Kaavat}.
%  Otaniemi, 2010. 390 pages.
%\bibitem{mellin10b}
%  Ilkka Mellin, 
%  \emph{Tilastolliset taulukot}.
%  Otaniemi, 2010. 13 pages.
\end{thebibliography}

\end{document}
